# ğŸ“ Proyecto: Web Scraper

## ğŸ“‹ DescripciÃ³n

Este proyecto es un scraper automatizado que extrae informaciÃ³n de libros desde el sitio [Books to Scrape](http://books.toscrape.com/), ideal para prÃ¡cticas de scraping y automatizaciÃ³n de tareas con Python.

Las tareas se almacenan de forma persistente en un archivo `JSON`.

---

## ğŸš€ TecnologÃ­as y herramientas utilizadas

- Python 3.x
- MÃ³dulos estÃ¡ndar: `time`, `urljoin`, `datetime`, `csv`
- MÃ³dulos externos: `bs4`, `requests`, `schedule`
- Formato de persistencia: csv
- Estilo de programaciÃ³n: modular

---

## âš™ï¸ CÃ³mo ejecutar el proyecto

1. Clona el repositorio.
2. Instala las dependencias:
   ```bash
   pip install -r requirements.txt
   ```
3. Ejecuta el scraper manualmente:
   ```bash
   python scraper.py
   ```
    o deja que corra de forma automatica:
   ```bash
    python scraper.py
    ```

## ğŸ’¡ Funcionalidades implementadas

- NavegaciÃ³n automÃ¡tica por todas las pÃ¡ginas del catÃ¡logo.
- ExtracciÃ³n de tÃ­tulo, precio, disponibilidad, calificaciÃ³n y enlace del libro.
- GeneraciÃ³n de archivo `.csv` con los resultados.
- Agendado automÃ¡tico del scraper para que se ejecute cada hora.
- Manejador de errores y fallos en la red.
- Nombres Ãºnicos por archivo usando `timestamp`.
- Estructura clara y mantenible con funciones bien definidas.

---

## ğŸ› ï¸ Posibles mejoras futuras

- Implementar un sistema de logs en archivo.
- Subida automÃ¡tica a Google Sheets o base de datos.
- Interfaz grÃ¡fica o visualizaciÃ³n con Streamlit.
- Guardado en otros formatos como JSON o Excel.

---

## âœ… Estado actual

- âœ”ï¸ Funcionalidad principal completada y probada.
- âœ”ï¸ AutomatizaciÃ³n con `schedule` integrada y operativa.
- âœ”ï¸ Buen manejo de errores y estructura de cÃ³digo modular.
- âœ”ï¸ Proyecto en fase **estable y finalizada**
